#character splitting with overlap
#seperate by paragraphs, or by dots + chunk sizem
#give IDs, and link chunks together
#add meta data to each chunk, like ID, semantic score with respect to the near documents, next, previous, document, number of charcaters, number of words
#semantic chunking
#AI chunking based on scenerio

#split by markdown in case there is code in the text or speical charctaers or HTML...


#what if there are images, tables with data, unstructured data. maybe with embeddings, vision?

#save sammru of each chunk in vector DB, so we can do sematic search based on higher level then choose th est document.
